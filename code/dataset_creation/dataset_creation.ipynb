{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bbb99ea",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Callable  \n",
    "import requests\n",
    "import os\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from empath import Empath\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d3c140",
   "metadata": {},
   "source": [
    "# Data screening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495b6ba",
   "metadata": {},
   "source": [
    "Upload the general and topic questions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_general = pd.read_csv(\"../../data/alexlab-storage-eu24-tk0__2024-09-16T08_59_07.939920__general.csv\")\n",
    "df_topic = pd.read_csv(\"../../data/alexlab-storage-eu24-tk0__2024-09-16T09_02_22.143201__topic.csv\")\n",
    "df_party = pd.read_csv(\"../dataset/General_Topic_Party.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65077f42",
   "metadata": {},
   "source": [
    "Extract data to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ffda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"Putin\", \"war\", \"abortion\", \"anti-war\", \"anti-abortion\"]\n",
    "df_combined = pd.concat([df_general, df_topic], ignore_index=True)\n",
    "df = df_combined[df_combined[\"search_queries\"].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "df = df.dropna()\n",
    "df = df[df[\"languages\"] == \"{'en'}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14381cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_general\n",
    "df = df.dropna()\n",
    "df = df[df[\"languages\"] == \"{'en'}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbca73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"war\", \"abortion\", \"anti-war\", \"anti-abortion\"]\n",
    "pattern = r'\\b(?:' + '|'.join(re.escape(k) for k in keywords) + r')\\b'\n",
    "df = df[df[\"captions\"].str.contains(pattern, case=False, na=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f08f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45171725",
   "metadata": {},
   "source": [
    "Determine the topic of each content (None, war-related or abortion-related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd21d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "war_keywords = [\"war\", \"anti-war\"]\n",
    "abortion_keywords = [\"abortion\", \"anti-abortion\"]\n",
    "\n",
    "def determine_topic(search_queries):\n",
    "    if pd.isna(search_queries):\n",
    "        return None\n",
    "    search_queries = str(search_queries).lower()\n",
    "    if any(keyword.lower() in search_queries for keyword in war_keywords):\n",
    "        return \"war\"\n",
    "    elif any(keyword.lower() in search_queries for keyword in abortion_keywords):\n",
    "        return \"abortion\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beccc3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'] = df['captions'].apply(determine_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f190d6e8",
   "metadata": {},
   "source": [
    "# Transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051de3b",
   "metadata": {},
   "source": [
    "Adaptation of the given script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd4f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by(lst: list, key_extractor: Callable):\n",
    "    d = defaultdict(list)\n",
    "    for item in lst:\n",
    "        d[key_extractor(item)].append(item)\n",
    "    return d\n",
    "\n",
    "# Script adapted from the one given by AIForesincs\n",
    "def get_transcripts_for_tiktok_video(video_id: str, transcripts_dir: Path):\n",
    "    video_url = f\"https://www.tiktok.com/@unknown/video/{video_id}\"\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/118.0\"\n",
    "    headers = {\n",
    "        \"User-Agent\": user_agent,\n",
    "        \"Referer\": \"https://www.tiktok.com/\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\"\n",
    "    }\n",
    "\n",
    "    print(f\"Fetching video URL: {video_url}\")\n",
    "    try:\n",
    "        response = requests.get(video_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching video URL: {e}\")\n",
    "        return None\n",
    "\n",
    "    html_content = response.text\n",
    "\n",
    "    # Extracting the JSON object from the HTML file\n",
    "    json_match = re.search(r'(?<=\"__DEFAULT_SCOPE__\":)[^<]*', html_content)\n",
    "    if not json_match:\n",
    "        print(\"JSON data not found in the HTML content.\")\n",
    "        return None\n",
    "\n",
    "    json_data = json.loads(json_match.group(0).strip()[:-1])  # manually removing last character\n",
    "    \n",
    "    # Validate JSON structure before accessing keys\n",
    "    if (\"webapp.video-detail\" not in json_data or\n",
    "        \"itemInfo\" not in json_data[\"webapp.video-detail\"] or\n",
    "        \"itemStruct\" not in json_data[\"webapp.video-detail\"][\"itemInfo\"] or\n",
    "        \"video\" not in json_data[\"webapp.video-detail\"][\"itemInfo\"][\"itemStruct\"] or\n",
    "        \"subtitleInfos\" not in json_data[\"webapp.video-detail\"][\"itemInfo\"][\"itemStruct\"][\"video\"]):\n",
    "        \n",
    "        print(f\"Unexpected JSON structure for video {video_id}. Skipping...\")\n",
    "        return None\n",
    "    \n",
    "    transcripts_infos = json_data[\"webapp.video-detail\"][\"itemInfo\"][\"itemStruct\"][\"video\"][\"subtitleInfos\"]\n",
    "\n",
    "    language_code_priority = [\n",
    "        \"eng-US\",\n",
    "        \"fra-FR\",\n",
    "        \"deu-DE\",\n",
    "        \"spa-ES\",\n",
    "    ]\n",
    "    subtitle_infos_by_format = group_by(transcripts_infos, lambda info: info[\"Format\"])\n",
    "    \n",
    "    captions = \"\"\n",
    "    \n",
    "    for subtitle_format, infos_list in subtitle_infos_by_format.items():\n",
    "        sorted_transcripts_infos_list = sorted(transcripts_infos,\n",
    "                                               key=lambda info: language_code_priority.index(\n",
    "                                                   info[\"LanguageCodeName\"]) if\n",
    "                                               info[\"LanguageCodeName\"] in language_code_priority else math.inf)\n",
    "        transcripts_info = sorted_transcripts_infos_list[0]\n",
    "        url = transcripts_info[\"Url\"]\n",
    "        language = transcripts_info[\"LanguageCodeName\"]\n",
    "        source = transcripts_info[\"Source\"]\n",
    "\n",
    "        suffix = \"vtt\" if subtitle_format == \"webvtt\" else \"json\" if subtitle_format == \"creator_caption\" else None\n",
    "\n",
    "        filename = f\"{video_id}_{subtitle_format}_{language}_{source}\"\n",
    "        if suffix:\n",
    "            filename += f\".{suffix}\"\n",
    "        try:\n",
    "            file_response = requests.get(url, headers=headers)\n",
    "            file_response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download transcripts for video {video_id}, language {language}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Storing content of the vtt file directly in the captions\n",
    "        captions = file_response.text\n",
    "\n",
    "        # Save file to disk\n",
    "        video_dir = transcripts_dir / str(video_id)\n",
    "\n",
    "        video_dir.mkdir(exist_ok=True)\n",
    "        with open(video_dir / filename, \"wb+\") as f:\n",
    "            f.write(file_response.content)\n",
    "            print(f\"Saved file: {video_dir / filename}\")\n",
    "    \n",
    "    return captions\n",
    "\n",
    "def add_captions_to_folder(df):\n",
    "        \n",
    "    for video_id in df['video_id']:\n",
    "        get_transcripts_for_tiktok_video(video_id, Path('./transcripts'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb3b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_captions_to_folder(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a42384",
   "metadata": {},
   "source": [
    "Addition of the \"captions\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_captions_to_df_vtt(df):\n",
    "    captions = []\n",
    "    \n",
    "    for video_id in df['video_id']:\n",
    "        # Find all VTT files for the given video_id. Since the video can end in different codes it is needed to end the direction with an *\n",
    "        vtt_files = list(Path(f'./transcripts/{video_id}').glob(f'{video_id}_webvtt_*.vtt'))\n",
    "        \n",
    "        if not vtt_files:\n",
    "            print(f\"Warning: No VTT files found for video {video_id}.\")\n",
    "            captions.append(\"\")  # Append empty caption if no files are found\n",
    "            continue\n",
    "        \n",
    "        # Use the first VTT file found (shouldn't be needed since every video just generates one caption)\n",
    "        vtt_file = vtt_files[0]\n",
    "        \n",
    "        # Check if the file is empty\n",
    "        if os.path.getsize(vtt_file) == 0:\n",
    "            print(f\"Warning: VTT file for video {video_id} is empty.\")\n",
    "            captions.append(\"\")  # Append empty caption if the file is empty\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with open(vtt_file, 'r', encoding='utf-8') as file:\n",
    "                vtt_lines = file.readlines()\n",
    "                \n",
    "                # Remove lines containing timestamps and 'WEBVTT' or if it contains a timestamp\n",
    "                caption_lines = [line.strip() for line in vtt_lines if '-->' not in line and line.strip() != 'WEBVTT']\n",
    "                \n",
    "                # Join the caption lines into one string\n",
    "                captions_text = ' '.join(caption_lines)\n",
    "                captions.append(captions_text)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for video {video_id}: {e}\")\n",
    "            captions.append(\"\")  # Append an empty caption for any other errors\n",
    "\n",
    "    df['captions'] = captions\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd38dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_captions_to_df_vtt(df)\n",
    "\n",
    "# Clean the results without captions\n",
    "df = df[df[\"captions\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c583fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.languages.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68350a15",
   "metadata": {},
   "source": [
    "# VADER: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490d055",
   "metadata": {},
   "source": [
    "Download the VADER lexicon (if not installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d818e05e",
   "metadata": {},
   "source": [
    "Create the VADER sentiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b15234",
   "metadata": {},
   "source": [
    "Add the binary and ternary classification sentiment score and the valence scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f86a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(row):\n",
    "    scores = {'pos': row['pos'], 'neg': row['neg'], 'neu': row['neu']}\n",
    "    dominant = max(scores, key=scores.get)\n",
    "    return 1 if dominant == 'pos' else -1 if dominant == 'neg' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2eb4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full VADER score dictionary\n",
    "df['scores'] = df['captions'].astype(str).apply(lambda text: sia.polarity_scores(text))\n",
    "\n",
    "# Extract individual scores\n",
    "df['sentiment_score_compound'] = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['pos'] = df['scores'].apply(lambda score_dict: score_dict['pos'])\n",
    "df['neg'] = df['scores'].apply(lambda score_dict: score_dict['neg'])\n",
    "df['neu'] = df['scores'].apply(lambda score_dict: score_dict['neu'])\n",
    "\n",
    "# Asign binary sentiment score: 1 positive and -1 negative, no neutral values taked into account\n",
    "df['sentiment_score_binary'] = df.apply(lambda row: 1 if row['pos'] > row['neg'] else -1, axis=1)\n",
    "\n",
    "# Assign ternary sentiment score: 1 for positive, -1 for negative, 0 for neutral\n",
    "df['sentiment_score_ternary'] = df.apply(classify_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bfca73",
   "metadata": {},
   "source": [
    "# Subjectivity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18fa4b9",
   "metadata": {},
   "source": [
    "Define the function that returns the subectivity score from textblob library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2008b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e58fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subjectivity_score'] = df['captions'].astype(str).apply(get_subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d6651",
   "metadata": {},
   "source": [
    "# Content analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c0c96",
   "metadata": {},
   "source": [
    "Initialize the Empath lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ee278",
   "metadata": {},
   "outputs": [],
   "source": [
    "empath_lexicon = Empath()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c11f86",
   "metadata": {},
   "source": [
    "Definition of the custom topic categories I want to compute the appearence score of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_categories():\n",
    "    categories = {\n",
    "        \"pro_stance\" :  [\"support\", \"approval\", \"agreement\", \"endorsement\", \"favor\", \"positive_opinion\", \"advocate\", \"in_favor\", \"backing\"], # Adding my own words per category\n",
    "        \"moral_dilemma\": [\"ethics\", \"morality\", \"controversy\", \"decision_making\", \"right_vs_wrong\"],\n",
    "        \"misinformation\": [\"fake_news\", \"disinformation\", \"propaganda\", \"conspiracy\", \"false_claims\"],\n",
    "        \"human_rights\": [\"freedom\", \"equality\", \"discrimination\", \"justice\", \"civil_rights\"],\n",
    "        \"abortion_rights\": [\"pro_choice\", \"pro_life\", \"reproductive_rights\", \"bodily_autonomy\", \"abortion_laws\"],\n",
    "        \"war_justification\": [\"military_intervention\", \"self_defense\", \"war_crimes\", \"peace_treaty\", \"conflict_resolution\"],\n",
    "        \"womens_rights\": [\"gender_equality\", \"feminism\", \"reproductive_rights\", \"pay_gap\", \"domestic_violence\"],\n",
    "        \"disagreement\": [\"oppose\", \"disagree\", \"rebuttal\", \"contradict\", \"objection\", \"refute\", \"challenge\", \"criticism\", \"conflict\", \"debate\", \"hate\"]\n",
    "    }\n",
    "\n",
    "    model = \"nytimes\"  # Using \"nytimes\" for a more policy-related vocabulary\n",
    "\n",
    "    for category, keywords in categories.items():\n",
    "        empath_lexicon.create_category(category, keywords, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_custom_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca12c33",
   "metadata": {},
   "source": [
    "List of all the expeted categories to be added, including the ones from Empath and the ones I crated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb170ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"pain\", \"movement\", \"negative_emotion\", \"religion\", \"violence\", \"government\", \n",
    "    \"independence\", \"fear\", \"trust\", \"leader\", \"pro_stance\", \"moral_dilemma\", \n",
    "    \"misinformation\", \"human_rights\", \"abortion_rights\", \"war_justification\", \"womens_rights\",\n",
    "    \"disagreement\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd66e59",
   "metadata": {},
   "source": [
    "Execute the content analysis for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab774157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text):\n",
    "    if pd.isna(text):  # Handle null values\n",
    "        return {category: 0.0 for category in categories}\n",
    "    return empath_lexicon.analyze(text, categories=categories, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df['captions'].apply(analyze_text).apply(pd.Series))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130c609",
   "metadata": {},
   "source": [
    "# Political Parties Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44cbf53",
   "metadata": {},
   "source": [
    "Create al list of the political entities according to their ideologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some abbrevatrions (such as PS for Belgium and France) might overlap\n",
    "# While there might be parties from all european countries, I have foccused on the countries included on the experiment\n",
    "\n",
    "left = [\n",
    "    \"Die Linke\", \"IU\", \"Podemos\", \"PCE\", \"PCF\", \"LFI\", \"PRC\", \"SI\", \"Syriza\",\n",
    "    \"BE\", \"Vänsterpartiet\", \"Vasemmistoliitto\", \"AKEL\", \"PTB\", \"KPÖ\",\n",
    "    \"SP\", \"Enhedslisten\", \"Rødt\", \"PST/POP\", \"PIE\", \"The Left\", \"Razem\", \"EFA\",\n",
    "    \"S&D\", \"Renew Europe\", \"PSOE\", \"Sumar\", \"PES\", \"PS\", \"APSD\", \"SD\", \"SAP\",\n",
    "    \"Labour\", \"SPÖ\", \"Vooruit\", \"SPD\", \"NL\", \"PvdA\", \"Socialist Party\",\n",
    "    \"Democratic Party\", \"Labour Party\", \"PASOK\", \"SLD\", \"Nouvelle Donne\", \"PRG\",\n",
    "    \"Inicjatywa Polska\", \"Grüne\", \"Greens\"\n",
    "]\n",
    "\n",
    "right = [\n",
    "    \"EPP\", \"ECR\", \"PiS\", \"VOX\", \"ID\", \"RN\", \"Lega\", \"FPÖ\", \"Fidesz\", \"Patriots\", \n",
    "    \"ESN\", \"AfD\", \"Republika\", \"Reconquête\", \"NOWA NADZIEJA\", \"Mi Hazánk\",\n",
    "    \"PP\", \"Partido Popular\", \"CDU\", \"Agir\", \"MoDem\", \"Ensemble\", \"LFA\", \"RE\",\n",
    "    \"LR\", \"CDA\", \"NSC\", \"IDP\", \"CSU\", \"FDP\", \"FW\", \"Junts\", \"ZP\", \"NPD\", \"PVV\",\n",
    "    \"FvD\", \"European People's Party\", \"Progressive Alliance of Socialists & Democrats\", \"PO\",\n",
    "    \"PSL\", \"BBB\", \"CDA\", \"NSC\", \"Familie\", \"ÖDP\", \"UDR\"]\n",
    "\n",
    "# It is possible that it is needed to change the abbr. of the parties with their full name so they are detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf99bbb",
   "metadata": {},
   "source": [
    "Socialist members are extracted from: https://en.wikipedia.org/wiki/Party_of_European_Socialists\n",
    "\n",
    "Center-left member are extracted from: https://en.wikipedia.org/wiki/Category:Centre-right_parties_in_Europe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca238b2e",
   "metadata": {},
   "source": [
    "Indicate the % of right and left parties mentioned, and lists all of the political parties mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21abaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ideology(description):\n",
    "    if not isinstance(description, str):  # Return default values if no description\n",
    "        return pd.Series([np.nan, 0.0, 0.0, []])\n",
    "\n",
    "    description_lower = description.lower()\n",
    "    left_lower = [party.lower() for party in left]\n",
    "    right_lower = [party.lower() for party in right]\n",
    "\n",
    "    found_left = [left[i] for i, party in enumerate(left_lower) if party in description_lower]\n",
    "    found_right = [right[i] for i, party in enumerate(right_lower) if party in description_lower]\n",
    "\n",
    "    parties_mentioned = found_left + found_right\n",
    "    total_found = len(parties_mentioned)\n",
    "\n",
    "    if total_found == 0:\n",
    "        perc_left = perc_right = 0.0\n",
    "        ideology = \"no mention\"\n",
    "    else:\n",
    "        perc_left = len(found_left) / total_found\n",
    "        perc_right = len(found_right) / total_found\n",
    "        if perc_left > perc_right:\n",
    "            ideology = \"left\"\n",
    "        elif perc_right > perc_left:\n",
    "            ideology = \"right\"\n",
    "        else:\n",
    "            ideology = \"mixed\"\n",
    "\n",
    "    return pd.Series([ideology, perc_left, perc_right, parties_mentioned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"ideology\", \"% left\", \"% right\", \"parties_mentioned\"]] = df[\"description\"].apply(analyze_ideology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0fd631",
   "metadata": {},
   "source": [
    "# Engagement Metrics: Likes and followers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b5c506",
   "metadata": {},
   "source": [
    "Function to translate letters on numbers to only numbers (1K --> 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_number(text):\n",
    "    text = text.upper().strip()\n",
    "    if 'K' in text:\n",
    "        return int(float(text.replace('K', '')) * 1_000)\n",
    "    elif 'M' in text:\n",
    "        return int(float(text.replace('M', '')) * 1_000_000)\n",
    "    elif 'B' in text:\n",
    "        return int(float(text.replace('B', '')) * 1_000_000_000)\n",
    "    return int(text.replace(',', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51917c6e",
   "metadata": {},
   "source": [
    "Get the likes and followers of each entry using the Selenium library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_likes_and_creator_followers_selenium(driver, video_id: str, creator_id: str):\n",
    "    video_url = f\"https://www.tiktok.com/@{creator_id}/video/{video_id}\"\n",
    "    creator_url = f\"https://www.tiktok.com/@{creator_id}\"\n",
    "\n",
    "    likes = None\n",
    "    followers = None\n",
    "\n",
    "    try:\n",
    "        # Charging the video page\n",
    "        driver.get(video_url)\n",
    "        time.sleep(3)  # Wait to ensure is all loaded\n",
    "\n",
    "        # Likes\n",
    "        like_element = driver.find_element(By.CSS_SELECTOR, '[data-e2e=\"like-count\"]')\n",
    "        likes = parse_number(like_element.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error obtaining likes for {video_id}: {e}\")\n",
    "\n",
    "    try:\n",
    "        \n",
    "        driver.get(creator_url)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Followers\n",
    "        follower_element = driver.find_element(By.CSS_SELECTOR, '[data-e2e=\"followers-count\"]')\n",
    "        followers = parse_number(follower_element.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error obtaining followers for  {creator_id}: {e}\")\n",
    "\n",
    "    return likes, followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba39f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_likes_and_followers_to_dataframe(df):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"likes\"] = None\n",
    "    df[\"followers\"] = None\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        video_id = row[\"video_id\"]\n",
    "        creator_id = row[\"creator_id\"]\n",
    "        print(f\"Processing @{creator_id} / video {video_id}...\")\n",
    "\n",
    "        likes, followers = get_video_likes_and_creator_followers_selenium(driver, video_id, creator_id)\n",
    "\n",
    "        df.at[index, \"likes\"] = likes\n",
    "        df.at[index, \"followers\"] = followers\n",
    "\n",
    "    driver.quit()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6b5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_likes_and_followers_to_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552648e",
   "metadata": {},
   "source": [
    "# Results storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc0d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/Final_TikTok.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f34b6f4",
   "metadata": {},
   "source": [
    "# Political parties detection Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252430eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"../dataset/General_Topic_ByTopic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some abbrevatrions (such as PS for Belgium and France) might overlap\n",
    "# While there might be parties from all european countries, I have foccused on the countries included on the experiment\n",
    "\n",
    "left = [\n",
    "    \"Die Linke\", \"IU\", \"Podemos\", \"PCE\", \"PCF\", \"LFI\", \"PRC\", \"Syriza\", \n",
    "    \"Vänsterpartiet\", \"Vasemmistoliitto\", \"AKEL\", \"PTB\", \"KPÖ\", \"Enhedslisten\", \n",
    "    \"Rødt\", \"PST/POP\", \"PIE\", \"The Left\", \"Razem\", \"EFA\", \"S&D\", \"Renew Europe\", \n",
    "    \"PSOE\", \"Partido Socialista Obrero Español\", \"Sumar\", \"PES\", \"PS\", \n",
    "    \"Parti Socialiste\", \"APSD\", \"SD\", \"SAP\", \"Labour\", \"SPÖ\", \"Vooruit\", \"SPD\", \n",
    "    \"Sozialdemokratische Partei Deutschlands\", \"NL\", \"Nowa Lewica\", \"PvdA\", \n",
    "    \"Partij van de Arbeid\", \"Socialist Party\", \"Democratic Party\", \"Labour Party\", \n",
    "    \"PASOK\", \"SLD\", \"Nouvelle Donne\", \"PRG\", \"Inicjatywa Polska\", \"Grüne\", \n",
    "    \"Greens\", \"ERC\", \"Esquerra Republicana de Catalunya\", \"EGP\", \"The Greens\", \n",
    "    \"BNG\", \"Bloque Nacionalista Galego\", \"LE\", \"Les Écologistes\", \"The greens\", \n",
    "    \"GL\", \"GroenLinks\", \"SMR\", \"Bildu\", \"Euskal Herria Bildu\", \"Left Party\", \"PvdD\", \n",
    "    \"Partij voor de Dieren\"\n",
    "]\n",
    "\n",
    "right = [\n",
    "    \"EPP\", \"European People's Party\", \"ECR\", \"PiS\", \"Law and Justice\", \"VOX\", \n",
    "    \"RN\", \"National Rally\", \"FPÖ\", \"Fidesz\", \"Patriots\", \"ESN\", \n",
    "    \"Europe of Sovereign Nations\", \"AfD\", \"Alternative für Deutschland\", \"Republika\", \n",
    "    \"Reconquête\", \"NOWA NADZIEJA\", \"New Hope\", \"Mi Hazánk\", \"PP\", \"Partido Popular\", \n",
    "    \"CDU\", \"Christlich Demokratische Union Deutschlands\", \"Agir\", \"MoDem\", \n",
    "    \"Mouvement Démocrate\", \"Ensemble\", \"LFA\", \"RE\", \"Renaissance\", \"LR\", \n",
    "    \"Les Républicains\", \"CDA\", \"Christen-Democratisch Appèl\", \"NSC\", \n",
    "    \"New Social Contract\", \"IDP\", \"CSU\", \"Christlich-Soziale Union in Bayern\", \n",
    "    \"FDP\", \"Freie Demokratische Partei\", \"FW\", \"Freie Wähler\", \"Junts\", \"ZP\", \"NPD\", \n",
    "    \"PVV\", \"Partij voor de Vrijheid\", \"FvD\", \"European People's Party\", \n",
    "    \"Progressive Alliance of Socialists & Democrats\", \"PO\", \"Platforma Obywatelska\", \n",
    "    \"PSL\", \"Polskie Stronnictwo Ludowe\", \"BBB\", \"BoerBurgerBeweging\", \"Familie\", \n",
    "    \"ÖDP\", \"Ökologisch-Demokratische Partei\", \"UDR\", \"Union des Démocrates et Indépendants\", \n",
    "    \"PfE\", \"Patriots of Europe\", \"D66\", \"Democraten 66\", \"PL2050\", \"Polska 2050\", \n",
    "    \"RECONQUÊTE\", \"R!\", \"NN\", \"Nieuwe Nationale Partij\"\n",
    "]\n",
    "\n",
    "# It is possible that it is needed to change the abbr. of the parties with their full name so they are detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_group_mapping = {\n",
    "    'EPP' : 'EPP',                      # -------- European People's Party --------\n",
    "    'PP': 'EPP',                        # Spain - Partido Popular\n",
    "    'PSL': 'EPP',                       # Poland\n",
    "    'PO': 'EPP',                        # Poland\n",
    "    'BBB': 'EPP',                       # Netherlands\n",
    "    'CDA': 'EPP',                       # Netherlands\n",
    "    'PVV': 'EPP',                       # Netherlands\n",
    "    'CDU': 'EPP',                       # Germany\n",
    "    'ÖDP': 'EPP',                       # Germany\n",
    "    'CSU': 'EPP',                       # Germany\n",
    "    'FAMILIE': 'EPP',                   # Germany\n",
    "    'LR': 'EPP',                        # France\n",
    "    'UDR' : 'EPP',                      # France\n",
    "    'S&D': 'S&D',                       # -------- European --------\n",
    "    'PSOE': 'S&D',                      # Spain\n",
    "    'SPD': 'S&D',                       # Germany\n",
    "    'NL' : 'S&D',                       # Poland - New Left\n",
    "    'PS' : 'S&D',                       # France - Parti Socialiste\n",
    "    'PvdA': 'S&D',                      # Netherlands - Labour Party\n",
    "    'PfE' : 'PfE',                      # -------- European Patriots of Europe --------\n",
    "    'VOX' : 'PfE',                      # Spain - Vox\n",
    "    'RN' : 'PfE',                       # France - National Rally || Poland - National Movement\n",
    "    'PVV' : 'PfE',                      # Netherlands - Party for Freedom\n",
    "    'ECR' : 'ECR',                      # -------- European Conservatives and Reformists --------\n",
    "    'SALF' : 'ECR',                     # Spain - Se acabo la fiesta\n",
    "    'IDL' : 'ECR',                      # France - Identity and Liberty\n",
    "    'PiS' : 'ECR',                      # Poland - Law and Justice\n",
    "    'SGP' : 'ECR',                      # Netherlands - Reformed Political Party\n",
    "    'Renew Europe' : 'Renew Europe',    # -------- Renew Europe --------\n",
    "    'PNV' : 'Renew Europe',             # Spain - Basque Nationalist Party\n",
    "    'MoDem' : 'Renew Europe',           # France - Democratic Movement\n",
    "    'RE' : 'Renew Europe',              # France - Renaissance\n",
    "    'UDI' : 'Renew Europe',             # France - Union of Democrats and Independents\n",
    "    'FDP' : 'Renew Europe',             # Germany - Free Democratic Party\n",
    "    'FW' : 'Renew Europe',              # Germany - Free Voters\n",
    "    'VVD' : 'Renew Europe',             # Netherlands - People's Party for Freedom and Democracy\n",
    "    'D66' : 'Renew Europe',             # Netherlands - Democrats 66\n",
    "    'PL2050' : 'Renew Europe',          # Poland - Poland 2050\n",
    "    'Greens' : 'Greens',                # -------- The Greens --------\n",
    "    'EFA' : 'Greens',                   # -------- European Free Alliance --------\n",
    "    'ERC' : 'Greens',                   # Spain - Republican Left of Catalonia\n",
    "    'BNG' : 'Greens',                   # Spain - Galician Nationalist Bloc\n",
    "    'EGP' : 'Greens',                   # European Green Party \n",
    "    'LE' : 'Greens',                    # France - Les Écologistes - The Greens \n",
    "    'The greens' : 'Greens',            # Germany - The Greens\n",
    "    'GL' : 'Greens',                    # Netherlands - GroenLinks\n",
    "    'The Left' : 'The Left',            # -------- The Left --------\n",
    "    'Podemos' : 'The Left',             # Spain - Podemos\n",
    "    'Sumar' : 'The Left',               # Spain - Sumar\n",
    "    'SMR' : 'The Left',                 # Spain - Sumar\n",
    "    'Bildu' : 'The Left',               # Spain - Bildu\n",
    "    'LFI' : 'The Left',                 # France - La France Insoumise\n",
    "    'Die Linke' : 'The Left',           # Germany - The Left\n",
    "    'Left party' : 'The Left',          # Germany - The Left\n",
    "    'PvdD' : 'The Left',                # Netherlands - Party for the Animals\n",
    "    'ESN' : 'ESN',                      # -------- Europe of Sovereign Nations --------\n",
    "    'RECONQUÊTE' : 'ESN',               # France - Reconquête\n",
    "    'R!' : 'ESN',                       # France - Reconquête\n",
    "    'AfD' : 'ESN',                      # Germany - Alternative for Germany\n",
    "    'NN' : 'ESN',                       # Netherlands - New Hope\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ideology(description):\n",
    "    if not isinstance(description, str):\n",
    "        return pd.Series([np.nan, 0.0, 0.0, []])\n",
    "\n",
    "    found_left = [\n",
    "        party for party in left\n",
    "        if re.search(r'\\b' + re.escape(party) + r'\\b', description, flags=re.IGNORECASE)\n",
    "    ]\n",
    "    found_right = [\n",
    "        party for party in right\n",
    "        if re.search(r'\\b' + re.escape(party) + r'\\b', description, flags=re.IGNORECASE)\n",
    "    ]\n",
    "\n",
    "    parties_mentioned = found_left + found_right\n",
    "    total_found = len(parties_mentioned)\n",
    "\n",
    "    if total_found == 0:\n",
    "        perc_left = perc_right = 0.0\n",
    "        ideology = \"no mention\"\n",
    "    else:\n",
    "        perc_left = len(found_left) / total_found\n",
    "        perc_right = len(found_right) / total_found\n",
    "        if perc_left > perc_right:\n",
    "            ideology = \"left\"\n",
    "        elif perc_right > perc_left:\n",
    "            ideology = \"right\"\n",
    "        else:\n",
    "            ideology = \"mixed\"\n",
    "\n",
    "    return pd.Series([ideology, perc_left, perc_right, parties_mentioned])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca196d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ideology(description, captions, search_query):\n",
    "    # Combine all text inputs into one string\n",
    "    combined_text = ' '.join([\n",
    "        str(description) if isinstance(description, str) else '',\n",
    "        str(captions) if isinstance(captions, str) else '',\n",
    "        str(search_query) if isinstance(search_query, str) else ''\n",
    "    ])\n",
    "\n",
    "    # Find matches\n",
    "    found_left = [\n",
    "        party for party in left\n",
    "        if re.search(r'\\b' + re.escape(party) + r'\\b', combined_text, flags=re.IGNORECASE)\n",
    "    ]\n",
    "    found_right = [\n",
    "        party for party in right\n",
    "        if re.search(r'\\b' + re.escape(party) + r'\\b', combined_text, flags=re.IGNORECASE)\n",
    "    ]\n",
    "\n",
    "    parties_mentioned = found_left + found_right\n",
    "    total_found = len(parties_mentioned)\n",
    "\n",
    "    if total_found == 0:\n",
    "        perc_left = perc_right = 0.0\n",
    "        ideology = \"no mention\"\n",
    "    else:\n",
    "        perc_left = len(found_left) / total_found\n",
    "        perc_right = len(found_right) / total_found\n",
    "        if perc_left > perc_right:\n",
    "            ideology = \"left\"\n",
    "        elif perc_right > perc_left:\n",
    "            ideology = \"right\"\n",
    "        else:\n",
    "            ideology = \"mixed\"\n",
    "\n",
    "    return pd.Series([ideology, perc_left, perc_right, parties_mentioned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4232a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile regex patterns\n",
    "left_pattern = r'\\b(?:' + '|'.join(map(re.escape, left)) + r')\\b'\n",
    "right_pattern = r'\\b(?:' + '|'.join(map(re.escape, right)) + r')\\b'\n",
    "\n",
    "# Count how many search_queries mention at least one left or right party\n",
    "left_mentions = df[\"search_queries\"].str.contains(left_pattern, case=False, regex=True).sum()\n",
    "right_mentions = df[\"search_queries\"].str.contains(right_pattern, case=False, regex=True).sum()\n",
    "\n",
    "print(f\"Search queries mentioning a left-aligned party: {left_mentions}\")\n",
    "print(f\"Search queries mentioning a right-aligned party: {right_mentions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15be576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"ideology\", \"% left\", \"% right\", \"parties_mentioned\"]] = df[\"search_query\"].apply(analyze_ideology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"ideology\", \"% left\", \"% right\", \"parties_mentioned\"]] = df.apply(\n",
    "    lambda row: analyze_ideology(row['description'], row['captions'], row['search_queries']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Final_TikTok.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b835b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/Final_TikTok.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"TikTokEuropeanElections_Abortion_War.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
