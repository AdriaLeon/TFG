{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91086912",
   "metadata": {},
   "source": [
    "Load the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e8a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../final_dataset_with_likes.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63e41f",
   "metadata": {},
   "source": [
    "# Bootstrapping the mean of the sentiment score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41b008",
   "metadata": {},
   "source": [
    "Bootstrapping in statistics is a form of hypothesis testing that involves resampling a single data set to create a multitude of simulated samples. This samples might be used to compute standard errors, confidence intervals...\n",
    "\n",
    "I will use it to compute the mean of the sentiment score in order to relate it with other features of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Defining the hyperparameters\n",
    "n_iterations = 1000\n",
    "sample_size = len(df)\n",
    "boot_means = []\n",
    "\n",
    "# Bootstrapping loop\n",
    "for i in range(n_iterations):\n",
    "    sample = df.sample(n=sample_size, replace=True)\n",
    "    mean = sample['sentiment_score'].mean()\n",
    "    boot_means.append(mean)\n",
    "\n",
    "# Calculating confidence interval\n",
    "ci_lower = np.percentile(boot_means, 2.5)\n",
    "ci_upper = np.percentile(boot_means, 97.5)\n",
    "\n",
    "# The mean of the whole population is between this two points\n",
    "print(f\"Bootstrapped 95% CI for 'sentiment_score': [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "\n",
    "# Plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(boot_means, bins=50, kde=True, color='skyblue')\n",
    "plt.axvline(ci_lower, color='red', linestyle='--', label=f'2.5% ({ci_lower:.3f})')\n",
    "plt.axvline(ci_upper, color='red', linestyle='--', label=f'97.5% ({ci_upper:.3f})')\n",
    "plt.axvline(np.mean(boot_means), color='green', linestyle='-', label=f'Mean ({np.mean(boot_means):.3f})')\n",
    "plt.title(\"Bootstrapped Means of Sentiment Score\")\n",
    "plt.xlabel(\"Mean Sentiment Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ec319",
   "metadata": {},
   "source": [
    "Conclusion: Since the sentiment score range is [-1,1], we can extract from here that most of the videos are slightly \"positive\" (at least when referring the vocabulary used) more than \"negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af513f0",
   "metadata": {},
   "source": [
    "Mean sentiment score depending on the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eaf04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_iterations = 1000\n",
    "boot_results = []\n",
    "\n",
    "# Group by topic and run bootstrapping for war and abortion\n",
    "topics_of_interest = ['war', 'abortion']\n",
    "topic_boot_means = {}\n",
    "\n",
    "for topic in topics_of_interest:\n",
    "    group = df[df['topic'].str.lower() == topic]  # Filter for war or abortion\n",
    "    scores = group['sentiment_score'].dropna()\n",
    "    \n",
    "    boot_means = []\n",
    "    for _ in range(n_iterations):\n",
    "        # Bootstrap sampling with replacement\n",
    "        sample = scores.sample(n=len(scores), replace=True)\n",
    "        boot_means.append(sample.mean())\n",
    "    \n",
    "    topic_boot_means[topic] = boot_means\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "boot_df = pd.DataFrame(topic_boot_means)\n",
    "\n",
    "# Calculate the observed difference in means between war and abortion\n",
    "observed_diff = boot_df['war'].mean() - boot_df['abortion'].mean()\n",
    "\n",
    "# Calculate the distribution of differences under the null hypothesis\n",
    "boot_diff = boot_df['war'].values - boot_df['abortion'].values\n",
    "\n",
    "# Calculate p-value (two-tailed test)\n",
    "p_value = np.mean(np.abs(boot_diff) >= np.abs(observed_diff))\n",
    "\n",
    "# Output the p-value\n",
    "print(f\"Observed difference in means: {observed_diff:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")\n",
    "\n",
    "# Plot the distributions of bootstrapped means for both topics\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(data=boot_df, palette='Set2', inner='quartile')\n",
    "plt.title(\"Bootstrapped Mean Sentiment Score for War and Abortion Topics\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Bootstrapped Mean Sentiment Score\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849f8be",
   "metadata": {},
   "source": [
    "The p-value is very high so there is no evidence that the difference between the two topics is very significant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03303874",
   "metadata": {},
   "source": [
    "Conclusion: As expected, both topics have a majority of positive vocabulary, this suggests that the language used in both topics, despite the challenging or sensitive nature, includes positive terms that may frame the topics in a way that encourages positive sentiments. \n",
    "\n",
    "Abortion related content has a grater score on most of the videos, since it is a associated to positive feelings such as \"independence\" or \"freedom\". These emotions are often connected with empowerment or rights which encourages positive sentiments. The negative sentiments for the war topic are reflected in the lower sentiment, as they are tied to the harsher and more distressing realities of war (deaths, destructions, sadness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of relevant topics\n",
    "topics = [\n",
    "    'pain', 'movement', 'negative_emotion', 'religion',\n",
    "    'violence', 'government', 'independence', 'fear', 'trust', 'leader',\n",
    "    'pro_stance', 'moral_dilemma', 'misinformation', 'human_rights',\n",
    "    'abortion_rights', 'war_justification', 'womens_rights'\n",
    "]\n",
    "\n",
    "# Filter for abortion and war videos\n",
    "abortion_df = df[df['topic'].str.lower().str.contains('abortion')]\n",
    "war_df = df[df['topic'].str.lower().str.contains('war')]\n",
    "\n",
    "# Calculate average scores for each topic in both subsets\n",
    "abortion_means = abortion_df[topics].mean()\n",
    "war_means = war_df[topics].mean()\n",
    "\n",
    "# Combine into a single DataFrame for comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Abortion': abortion_means,\n",
    "    'War': war_means\n",
    "})\n",
    "\n",
    "# Plot side-by-side bars\n",
    "comparison_df.plot(kind='bar', figsize=(15, 6), colormap='Set2')\n",
    "plt.title(\"Topic Intensity Comparison: Abortion vs. War Videos\")\n",
    "plt.ylabel(\"Average Topic Score\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Topic Category')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4ee5a",
   "metadata": {},
   "source": [
    "As we can see on this table, on war-related content we find more sentiments that can be related with negative ideas such as pain, violence, fear or (as expected) negative emotion. The only other sentiment where there is a noticeable difference is when the idea of is mentioned \"leader\".\n",
    "\n",
    "To determine wether this ideas impact the sentiment score by themselves we can check their relation directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60864bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of topics of interest\n",
    "topics = [\n",
    "    'subjectivity', 'pain', 'movement', 'negative_emotion', 'religion',\n",
    "    'violence', 'government', 'independence', 'fear', 'trust', 'leader',\n",
    "    'pro_stance', 'moral_dilemma', 'misinformation', 'human_rights',\n",
    "    'abortion_rights', 'war_justification', 'womens_rights'\n",
    "]\n",
    "\n",
    "# Function to perform bootstrapping and return the mean sentiment score\n",
    "def bootstrap_mean(data, n_iterations=1000):\n",
    "    means = []\n",
    "    for _ in range(n_iterations):\n",
    "        sample = data.sample(n=len(data), replace=True)\n",
    "        means.append(sample['sentiment_score'].mean())\n",
    "    return np.mean(means)\n",
    "\n",
    "# Dictionary to hold the bootstrap mean sentiment scores for each topic\n",
    "bootstrap_topic_scores = {}\n",
    "\n",
    "# Compute the bootstrap mean sentiment score for each topic\n",
    "for topic in topics:\n",
    "    subset = df[df[topic] > 0]  # Filter rows where the topic score is greater than 0\n",
    "    if not subset.empty:\n",
    "        mean_boot = bootstrap_mean(subset)\n",
    "        bootstrap_topic_scores[topic] = mean_boot\n",
    "\n",
    "# Sort the bootstrap scores in descending order\n",
    "bootstrap_topic_scores_sorted = dict(sorted(bootstrap_topic_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Output the results\n",
    "print(\"Bootstrap Mean Sentiment Scores for each Topic:\")\n",
    "for topic, score in bootstrap_topic_scores_sorted.items():\n",
    "    print(f\"{topic}: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f39dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "scores_df = pd.DataFrame(list(bootstrap_topic_scores_sorted.items()), columns=['Topic', 'Bootstrap Mean Sentiment Score'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=scores_df, x='Bootstrap Mean Sentiment Score', y='Topic', palette='viridis')\n",
    "plt.title('Bootstrap Mean Sentiment Scores by Topic')\n",
    "plt.xlabel('Mean Sentiment Score')\n",
    "plt.ylabel('Topic')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af813649",
   "metadata": {},
   "source": [
    "As contrary as I was expecting, the sentiments that were related to war content is not intrinsically negative, on the contrary, most of the ideas we have seen on the analysis performed before are associated to positive sentiment scores.\n",
    "\n",
    "This means that the negative tone must come from another source, we can try investigation the geographical influence and the political ideology to find answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a25c190",
   "metadata": {},
   "source": [
    "Finally, we can work with the correlation between topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the list of topics\n",
    "topics = [\n",
    "    'subjectivity', 'pain', 'movement', 'negative_emotion', 'religion',\n",
    "    'violence', 'government', 'independence', 'fear', 'trust', 'leader',\n",
    "    'pro_stance', 'moral_dilemma', 'misinformation', 'human_rights',\n",
    "    'abortion_rights', 'war_justification', 'womens_rights'\n",
    "]\n",
    "\n",
    "# Extract topic data from the DataFrame (make sure df is already defined)\n",
    "topic_data = df[topics].dropna()\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = topic_data.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True,\n",
    "            cbar_kws={\"label\": \"Correlation Coefficient\"})\n",
    "plt.title(\"Correlation Matrix Between Topics\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205147f",
   "metadata": {},
   "source": [
    "# Differences between countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e9bfb",
   "metadata": {},
   "source": [
    "Sentiment score by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8bbcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf4d6bd8",
   "metadata": {},
   "source": [
    "All five countries exhibit a general trend of maintaining a positive mean sentiment score. However, Poland and Germany report the lowest sentiment scores among them. These discrepancies can be attributed to the distinct sociopolitical contexts each country faces.\n",
    "\n",
    "While both Poland and Germany have long since legalized abortion, their geographical proximity to the ongoing Russia-Ukraine conflict may contribute to a heightened awareness of the surrounding geopolitical tensions. This proximity could lead to a more somber or negative tone in discussions surrounding sensitive topics such as abortion and war, in contrast to the other countries in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62996d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of bootstrap iterations\n",
    "n_iterations = 1000\n",
    "\n",
    "# Function to compute bootstrapped confidence intervals\n",
    "def bootstrap_ci(data, n_iterations=1000, percentile_range=(2.5, 97.5)):\n",
    "    boot_means = []\n",
    "    for _ in range(n_iterations):\n",
    "        sample = data.sample(n=len(data), replace=True)\n",
    "        boot_means.append(sample.mean())\n",
    "    ci_lower = np.percentile(boot_means, percentile_range[0])\n",
    "    ci_upper = np.percentile(boot_means, percentile_range[1])\n",
    "    return ci_lower, ci_upper\n",
    "\n",
    "# Create a combined plot for all countries\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Loop through each country in the dataframe\n",
    "for country, group in df.groupby('countries'):\n",
    "    # Iterate through each topic within the country\n",
    "    for topic, topic_data in group.groupby('topic'):\n",
    "        # Get bootstrapped confidence intervals for the sentiment score of each topic\n",
    "        ci_lower, ci_upper = bootstrap_ci(topic_data['sentiment_score'])\n",
    "        \n",
    "        # Plot the confidence intervals, using country as a label for each line\n",
    "        plt.plot([topic, topic], [ci_lower, ci_upper], marker='o', markersize=8, label=f'{country} - {topic}')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Bootstrapped 95% CI of Sentiment Scores by Topic and Country')\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a legend to differentiate countries\n",
    "plt.legend(title='Country - Topic', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff4d24",
   "metadata": {},
   "source": [
    "As expected both Poland and Germany have the lower sentiment scores when talking about both topics. While we could argue that this is due to geological reasons (in the case of war-content) we still need to find a reason behind the abortion negativeness.\n",
    "\n",
    "Low sentiment score when referring to abortion could be explained by the presence of right-associated ideology which is usually relation to anti-abortion discourse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac33c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by country and calculate mean for '% left' and '% right'\n",
    "mean_ideology = df.groupby('countries')[['% left', '% right']].mean().reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(mean_ideology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd41a91",
   "metadata": {},
   "source": [
    "While most of the countries have a majority of left %, Poland holds the biggest amount of right-political parties mentioned. \n",
    "\n",
    "So lets see if mentioning right political parties is related to having a lower sentiment score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225700c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Filter for abortion-related content\n",
    "abortion_df = df[df['topic'].str.lower() == 'abortion']\n",
    "\n",
    "# 2. Drop rows with missing values in sentiment or % right\n",
    "abortion_clean = abortion_df[['sentiment_score', '% right']].dropna()\n",
    "\n",
    "# 3. Correlation\n",
    "correlation = abortion_clean['sentiment_score'].corr(abortion_clean['% right'])\n",
    "print(f\"Correlation between sentiment score and % right (abortion videos): {correlation:.3f}\")\n",
    "\n",
    "# 4. Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(data=abortion_clean, x='% right', y='sentiment_score', scatter_kws={'s': 50}, line_kws={'color': 'red'})\n",
    "plt.title('Sentiment Score vs % Right (Abortion Content)')\n",
    "plt.xlabel('% Right')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3e5b6",
   "metadata": {},
   "source": [
    "As observed, there is a negative correlation between the percentage of right-leaning language and sentiment score in abortion-related content. This suggests that a higher presence of right-leaning ideological framing is associated with more negative sentiment when discussing abortion.\n",
    "\n",
    "This pattern could help explain Poland’s notably low sentiment scores, as it is the country with the highest percentage of right-leaning discourse in the dataset. In contrast, this explanation does not fully apply to Germany, which also shows lower sentiment scores but does not exhibit a particularly elevated % Right value. Therefore, in Germany’s case, the negative sentiment may stem from other sociopolitical factors or thematic nuances in the content rather than ideological framing alone.\n",
    "\n",
    "That is why it will be interesting to study how the other factors of the dataset might affect the sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0990923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by country and topic, then compute the mean pro_stance\n",
    "grouped = df.groupby(['countries', 'topic'])['pro_stance'].mean().reset_index()\n",
    "\n",
    "# Pivot the table\n",
    "pivot = grouped.pivot(index='countries', columns='topic', values='pro_stance')\n",
    "\n",
    "# Determine min and max for consistent color scaling\n",
    "vmin = pivot.min().min()\n",
    "vmax = pivot.max().max()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_filled = pivot.fillna(0)\n",
    "sns.heatmap(pivot_filled, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=0, vmax=1)\n",
    "plt.title(\"Average Pro Stance by Country and Topic (War vs Abortion)\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b320f7",
   "metadata": {},
   "source": [
    "Finally, it is also interesting to generally analysis whether the % of right and left parties mentioned influences the sentiment score to see if this is an isolated case for abortion or if it holds for both topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cefc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Filter for war-related content\n",
    "war_df = df[df['topic'].str.lower() == 'war']\n",
    "\n",
    "# 2. Drop missing values\n",
    "war_clean = war_df[['sentiment_score', '% right', '% left']].dropna()\n",
    "\n",
    "# 3. Reshape the data\n",
    "war_melted = war_clean.melt(id_vars='sentiment_score',\n",
    "                            value_vars=['% right', '% left'],\n",
    "                            var_name='Ideology',\n",
    "                            value_name='Percentage')\n",
    "\n",
    "# 4. Plot using lmplot\n",
    "sns.lmplot(\n",
    "    data=war_melted,\n",
    "    x='Percentage',\n",
    "    y='sentiment_score',\n",
    "    hue='Ideology',\n",
    "    height=6,\n",
    "    aspect=1.5,\n",
    "    scatter_kws={'alpha': 0.4},\n",
    "    line_kws={'linewidth': 2}\n",
    ")\n",
    "\n",
    "plt.title('Sentiment Score vs % Right / % Left (War Content)')\n",
    "plt.xlabel('% Ideological Mentions')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa40532e",
   "metadata": {},
   "source": [
    "In this case, the most the % of right political parties mentioned the lower the sentiment score is, so we can't not generalize the statement done before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee73de",
   "metadata": {},
   "source": [
    "Which topics are the most mentioned by country? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a3b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of emotion-related columns\n",
    "emotion_columns = [\n",
    "    \"negative_emotion\", \"fear\", \"trust\", \"pain\", \"movement\", \"religion\", \"violence\",\n",
    "    \"government\", \"independence\", \"leader\", \"pro_stance\", \"moral_dilemma\", \"misinformation\",\n",
    "    \"human_rights\", \"abortion_rights\", \"war_justification\", \"womens_rights\"\n",
    "]\n",
    "\n",
    "# Create a function to get the most common emotion for each country and topic\n",
    "def get_most_common_emotion(group):\n",
    "    # Calculate the mean for each emotion column\n",
    "    mean_emotions = group[emotion_columns].mean()\n",
    "    \n",
    "    # Find the emotion with the highest average value\n",
    "    most_common_emotion = mean_emotions.idxmax()\n",
    "    highest_value = mean_emotions.max()\n",
    "    \n",
    "    return pd.Series({\n",
    "        'most_common_emotion': most_common_emotion,\n",
    "        'emotion_value': highest_value\n",
    "    })\n",
    "\n",
    "# Apply the function to group by country and topic\n",
    "common_emotions = df.groupby(['countries', 'topic']).apply(get_most_common_emotion).reset_index()\n",
    "\n",
    "# Create a pivot table for the heatmap visualization\n",
    "pivot_table = common_emotions.pivot(index=\"countries\", columns=\"topic\", values=\"most_common_emotion\")\n",
    "\n",
    "# Create a numeric mapping for the emotions (only for heatmap coloring purposes)\n",
    "emotion_map = {emotion: idx for idx, emotion in enumerate(emotion_columns)}\n",
    "\n",
    "# Map the emotions in the common_emotions DataFrame to their numeric values for visualization\n",
    "common_emotions['emotion_numeric'] = common_emotions['most_common_emotion'].map(emotion_map)\n",
    "\n",
    "# Create a pivot table with numeric emotion values\n",
    "pivot_table_numeric = common_emotions.pivot(index=\"countries\", columns=\"topic\", values=\"emotion_numeric\")\n",
    "\n",
    "# Visualize as a heatmap with numeric values (using annotations for emotion names)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pivot_table_numeric, annot=pivot_table, cmap=\"coolwarm\", cbar=True, fmt=\"s\", \n",
    "            linewidths=0.5, annot_kws={\"size\": 8})\n",
    "plt.title(\"Most Common Emotion by Country and Topic\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of emotion-related columns\n",
    "emotion_columns = [\n",
    "    \"negative_emotion\", \"fear\", \"trust\", \"pain\", \"movement\", \"religion\", \"violence\",\n",
    "    \"government\", \"independence\", \"leader\", \"pro_stance\", \"moral_dilemma\", \"misinformation\",\n",
    "    \"human_rights\", \"abortion_rights\", \"war_justification\", \"womens_rights\"\n",
    "]\n",
    "\n",
    "# Create a function to get the top 5 emotions for each country and topic\n",
    "def get_top_5_emotions(group):\n",
    "    # Calculate the mean for each emotion column\n",
    "    mean_emotions = group[emotion_columns].mean()\n",
    "    \n",
    "    # Sort the emotions by their average value in descending order\n",
    "    sorted_emotions = mean_emotions.sort_values(ascending=False)\n",
    "    \n",
    "    # Get the top 5 emotions\n",
    "    top_5_emotions = sorted_emotions.head(5)\n",
    "    \n",
    "    return pd.Series({\n",
    "        'top_5_emotions': top_5_emotions.index.tolist(),\n",
    "        'top_5_values': top_5_emotions.values.tolist()\n",
    "    })\n",
    "\n",
    "# Apply the function to group by country and topic\n",
    "top_emotions = df.groupby(['countries', 'topic']).apply(get_top_5_emotions).reset_index()\n",
    "\n",
    "# Create a table that lists the top 5 emotions\n",
    "top_emotions_table = top_emotions.pivot(index=\"countries\", columns=\"topic\", values=\"top_5_emotions\")\n",
    "\n",
    "# Format the table to display emotions as comma-separated strings\n",
    "top_emotions_table = top_emotions_table.applymap(lambda x: \", \".join(x))\n",
    "\n",
    "# Plotting the top emotions as a table\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Create a table within the plot\n",
    "table = ax.table(cellText=top_emotions_table.values,\n",
    "                rowLabels=top_emotions_table.index,\n",
    "                colLabels=top_emotions_table.columns,\n",
    "                loc='center', cellLoc='center')\n",
    "\n",
    "# Customize the table appearance\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(8)\n",
    "table.scale(1.5, 1.5)\n",
    "\n",
    "plt.title(\"Top 5 Emotions by Country and Topic\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4447f8",
   "metadata": {},
   "source": [
    "# Relating sentiment score with engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the relevant columns\n",
    "cols = ['sentiment_score', 'average_order', 'likes', 'followers']\n",
    "subset = df[cols].dropna()\n",
    "\n",
    "# Pearson correlation\n",
    "correlation_matrix = subset.corr()\n",
    "\n",
    "print(correlation_matrix['sentiment_score'])\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.regplot(data=subset, x='average_order', y='sentiment_score', ax=axes[0], scatter_kws={'alpha':0.3})\n",
    "axes[0].set_title('Sentiment vs. Average Order')\n",
    "\n",
    "sns.regplot(data=subset, x='likes', y='sentiment_score', ax=axes[1], scatter_kws={'alpha':0.3})\n",
    "axes[1].set_title('Sentiment vs. Likes')\n",
    "\n",
    "sns.regplot(data=subset, x='followers', y='sentiment_score', ax=axes[2], scatter_kws={'alpha':0.3})\n",
    "axes[2].set_title('Sentiment vs. Followers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5014e199",
   "metadata": {},
   "source": [
    "The Pearson correlation analysis reveals a very weak negative relationship between sentiment score and both likes (r = -0.09) and followers (r = -0.09). These low coefficients suggest that sentiment is not significantly associated with user engagement, at least in terms of popularity metrics such as likes or follower count.\n",
    "\n",
    "Although the regression plots display a slight downward trend (indicating that higher engagement may coincide with more negative sentiment) this effect appears to be largely driven by a small number of high-engagement outliers. As such, the visual pattern lacks statistical support and should be interpreted with caution.\n",
    "\n",
    "In contrast, the correlation with average order is slightly stronger but still weak (r = 0.15). Interestingly, this weak positive correlation also hints at a possible tendency for videos with lower sentiment scores to rank more prominently, echoing the pattern seen in the plots.\n",
    "\n",
    "While further analysis falls beyond the scope of this work, it would be worth exploring whether content with more negative sentiment tends to perform better or gain more visibility, potentially due to emotional engagement or platform-specific dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e8027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Drop rows with missing values in the relevant columns\n",
    "df_clean = df[['likes', 'followers', '% left', '% right']].dropna()\n",
    "\n",
    "# Group by % left and calculate mean likes and followers\n",
    "mean_by_left = df_clean.groupby('% left')[['likes', 'followers']].mean().reset_index()\n",
    "mean_by_left.columns = ['% left', 'mean_likes_left', 'mean_followers_left']\n",
    "\n",
    "# Group by % right and calculate mean likes and followers\n",
    "mean_by_right = df_clean.groupby('% right')[['likes', 'followers']].mean().reset_index()\n",
    "mean_by_right.columns = ['% right', 'mean_likes_right', 'mean_followers_right']\n",
    "\n",
    "# Show the first few rows\n",
    "print(\"Mean Likes and Followers by % Left:\")\n",
    "print(mean_by_left.head())\n",
    "\n",
    "print(\"\\nMean Likes and Followers by % Right:\")\n",
    "print(mean_by_right.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9fd6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean likes vs % left and % right\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Likes\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(mean_by_left['% left'], mean_by_left['mean_likes_left'], label='Likes (% Left)', color='blue')\n",
    "plt.plot(mean_by_right['% right'], mean_by_right['mean_likes_right'], label='Likes (% Right)', color='red')\n",
    "plt.title('Mean Likes by Ideological Percentage')\n",
    "plt.xlabel('Ideological %')\n",
    "plt.ylabel('Mean Likes')\n",
    "plt.legend()\n",
    "\n",
    "# Followers\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(mean_by_left['% left'], mean_by_left['mean_followers_left'], label='Followers (% Left)', color='blue')\n",
    "plt.plot(mean_by_right['% right'], mean_by_right['mean_followers_right'], label='Followers (% Right)', color='red')\n",
    "plt.title('Mean Followers by Ideological Percentage')\n",
    "plt.xlabel('Ideological %')\n",
    "plt.ylabel('Mean Followers')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1e31f",
   "metadata": {},
   "source": [
    "For the likes, it seems like the more the videos only mention one political side the most likes they get, being the ones that are more \"neutrals\" are the one getting less engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f2872",
   "metadata": {},
   "source": [
    "Relate the subjectivity with the engagement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the relevant columns\n",
    "df_clean = df[['subjectivity', 'average_order', 'likes', 'followers']].dropna()\n",
    "\n",
    "# Correlation between subjectivity and other variables\n",
    "correlation_order = df_clean['subjectivity'].corr(df_clean['average_order'])\n",
    "correlation_likes = df_clean['subjectivity'].corr(df_clean['likes'])\n",
    "correlation_followers = df_clean['subjectivity'].corr(df_clean['followers'])\n",
    "\n",
    "print(f\"Correlation between subjectivity and order of appearance: {correlation_order:.3f}\")\n",
    "print(f\"Correlation between subjectivity and likes: {correlation_likes:.3f}\")\n",
    "print(f\"Correlation between subjectivity and followers: {correlation_followers:.3f}\")\n",
    "\n",
    "# Plotting the relationships\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Subjectivity vs Order of Appearance\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.regplot(data=df_clean, x='average_order', y='subjectivity', scatter_kws={'alpha':0.3}, line_kws={'color': 'red'})\n",
    "plt.title('Subjectivity vs Order of Appearance')\n",
    "plt.xlabel('Order of Appearance')\n",
    "plt.ylabel('Subjectivity')\n",
    "\n",
    "# Plot Subjectivity vs Likes\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.regplot(data=df_clean, x='likes', y='subjectivity', scatter_kws={'alpha':0.3}, line_kws={'color': 'red'})\n",
    "plt.title('Subjectivity vs Likes')\n",
    "plt.xlabel('Likes')\n",
    "plt.ylabel('Subjectivity')\n",
    "\n",
    "# Plot Subjectivity vs Followers\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.regplot(data=df_clean, x='followers', y='subjectivity', scatter_kws={'alpha':0.3}, line_kws={'color': 'red'})\n",
    "plt.title('Subjectivity vs Followers')\n",
    "plt.xlabel('Followers')\n",
    "plt.ylabel('Subjectivity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f2ec98",
   "metadata": {},
   "source": [
    "# Right and left differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db878a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the relevant columns\n",
    "df_clean = df[['subjectivity', '% left', '% right']].dropna()\n",
    "\n",
    "# Correlation between % left, % right, and subjectivity\n",
    "correlation_left = df_clean['subjectivity'].corr(df_clean['% left'])\n",
    "correlation_right = df_clean['subjectivity'].corr(df_clean['% right'])\n",
    "\n",
    "print(f\"Correlation between subjectivity and % left: {correlation_left:.3f}\")\n",
    "print(f\"Correlation between subjectivity and % right: {correlation_right:.3f}\")\n",
    "\n",
    "# Plotting the relationships\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Subjectivity vs % Left\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.regplot(data=df_clean, x='% left', y='subjectivity', scatter_kws={'alpha':0.3}, line_kws={'color': 'red'})\n",
    "plt.title('Subjectivity vs % Left')\n",
    "plt.xlabel('% Left')\n",
    "plt.ylabel('Subjectivity')\n",
    "\n",
    "# Plot Subjectivity vs % Right\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.regplot(data=df_clean, x='% right', y='subjectivity', scatter_kws={'alpha':0.3}, line_kws={'color': 'red'})\n",
    "plt.title('Subjectivity vs % Right')\n",
    "plt.xlabel('% Right')\n",
    "plt.ylabel('Subjectivity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
