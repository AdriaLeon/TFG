{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the general questions dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/alexlab-storage-eu24-tk0__2024-09-16T08_59_07.939920__general.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the data is correctly uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will just keep entries that have no-null entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop data of media that is not in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df[df[\"languages\"] == \"{'en'}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the transcripts folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Callable  # Add this import\n",
    "import requests\n",
    "\n",
    "\n",
    "def group_by(lst: list, key_extractor: Callable):\n",
    "    d = defaultdict(list)\n",
    "    for item in lst:\n",
    "        d[key_extractor(item)].append(item)\n",
    "    return d\n",
    "\n",
    "\n",
    "def get_transcripts_for_tiktok_video(video_id: str, transcripts_dir: Path):\n",
    "    video_url = f\"https://www.tiktok.com/@unknown/video/{video_id}\"\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/118.0\"\n",
    "    headers = {\n",
    "        \"User-Agent\": user_agent,\n",
    "        \"Referer\": \"https://www.tiktok.com/\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\"\n",
    "    }\n",
    "\n",
    "    print(f\"Fetching video URL: {video_url}\")\n",
    "    try:\n",
    "        response = requests.get(video_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching video URL: {e}\")\n",
    "        return None\n",
    "\n",
    "    html_content = response.text\n",
    "\n",
    "    # Extracting the JSON object from the HTML file\n",
    "    json_match = re.search(r'(?<=\"__DEFAULT_SCOPE__\":)[^<]*', html_content)\n",
    "    if not json_match:\n",
    "        print(\"JSON data not found in the HTML content.\")\n",
    "        return None\n",
    "\n",
    "    json_data = json.loads(json_match.group(0).strip()[:-1])  # manually removing last character\n",
    "    transcripts_infos = json_data[\"webapp.video-detail\"][\"itemInfo\"][\"itemStruct\"][\"video\"][\"subtitleInfos\"]\n",
    "\n",
    "    language_code_priority = [\n",
    "        \"eng-US\",\n",
    "        \"fra-FR\",\n",
    "        \"deu-DE\",\n",
    "        \"spa-ES\",\n",
    "    ]\n",
    "    subtitle_infos_by_format = group_by(transcripts_infos, lambda info: info[\"Format\"])\n",
    "    \n",
    "    captions = \"\"\n",
    "    \n",
    "    for subtitle_format, infos_list in subtitle_infos_by_format.items():\n",
    "        sorted_transcripts_infos_list = sorted(transcripts_infos,\n",
    "                                               key=lambda info: language_code_priority.index(\n",
    "                                                   info[\"LanguageCodeName\"]) if\n",
    "                                               info[\"LanguageCodeName\"] in language_code_priority else math.inf)\n",
    "        transcripts_info = sorted_transcripts_infos_list[0]\n",
    "        url = transcripts_info[\"Url\"]\n",
    "        language = transcripts_info[\"LanguageCodeName\"]\n",
    "        source = transcripts_info[\"Source\"]\n",
    "\n",
    "        suffix = \"vtt\" if subtitle_format == \"webvtt\" else \"json\" if subtitle_format == \"creator_caption\" else None\n",
    "\n",
    "        filename = f\"{video_id}_{subtitle_format}_{language}_{source}\"\n",
    "        if suffix:\n",
    "            filename += f\".{suffix}\"\n",
    "        try:\n",
    "            file_response = requests.get(url, headers=headers)\n",
    "            file_response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download transcripts for video {video_id}, language {language}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Storing content of the vtt file directly in the captions\n",
    "        captions = file_response.text\n",
    "\n",
    "        # Save file to disk (optional, if you need it later)\n",
    "        video_dir = transcripts_dir / str(video_id)\n",
    "\n",
    "        video_dir.mkdir(exist_ok=True)\n",
    "        with open(video_dir / filename, \"wb+\") as f:\n",
    "            f.write(file_response.content)\n",
    "            print(f\"Saved file: {video_dir / filename}\")\n",
    "    \n",
    "    return captions\n",
    "\n",
    "def add_captions_to_dataframe(df):\n",
    "    \n",
    "    # Remove undesired lines of the vtt file\n",
    "    # INPUT: Pandas df with a column named \"video_id\"\n",
    "    # OUTPUT: String containing just the text on a single line\n",
    "        \n",
    "    for video_id in df['video_id']:\n",
    "        get_transcripts_for_tiktok_video(video_id, Path('./transcripts'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_en.iloc[:4].copy()\n",
    "df_test = add_captions_to_dataframe(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the \"captions\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def add_captions_to_df_vtt(df):\n",
    "    captions = []\n",
    "    \n",
    "    for video_id in df['video_id']:\n",
    "        # Find all VTT files for the given video_id. Since the video can end in different codes it is needed to end the direction with an *\n",
    "        vtt_files = list(Path(f'./transcripts/{video_id}').glob(f'{video_id}_webvtt_*.vtt'))\n",
    "        \n",
    "        if not vtt_files:\n",
    "            print(f\"Warning: No VTT files found for video {video_id}.\")\n",
    "            captions.append(\"\")  # Append empty caption if no files are found\n",
    "            continue\n",
    "        \n",
    "        # Use the first VTT file found (shouldn't be needed since every video just generates one caption)\n",
    "        vtt_file = vtt_files[0]\n",
    "        \n",
    "        # Check if the file is empty\n",
    "        if os.path.getsize(vtt_file) == 0:\n",
    "            print(f\"Warning: VTT file for video {video_id} is empty.\")\n",
    "            captions.append(\"\")  # Append empty caption if the file is empty\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with open(vtt_file, 'r', encoding='utf-8') as file:\n",
    "                vtt_lines = file.readlines()\n",
    "                \n",
    "                # Remove lines containing timestamps and 'WEBVTT' or if it contains a timestamp\n",
    "                caption_lines = [line.strip() for line in vtt_lines if '-->' not in line and line.strip() != 'WEBVTT']\n",
    "                \n",
    "                # Join the caption lines into one string\n",
    "                captions_text = ' '.join(caption_lines)\n",
    "                captions.append(captions_text)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for video {video_id}: {e}\")\n",
    "            captions.append(\"\")  # Append an empty caption for any other errors\n",
    "\n",
    "    df['captions'] = captions\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = add_captions_to_df_vtt(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[df_test[\"captions\"] != \"\"]\n",
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
