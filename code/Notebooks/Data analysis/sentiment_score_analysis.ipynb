{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91086912",
   "metadata": {},
   "source": [
    "Load the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e8a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../final_dataset_with_likes.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63e41f",
   "metadata": {},
   "source": [
    "# Bootstrapping the mean of the sentiment score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41b008",
   "metadata": {},
   "source": [
    "Bootstrapping in statistics is a form of hypothesis testing that involves resampling a single data set to create a multitude of simulated samples. This samples might be used to compute standard errors, confidence intervals...\n",
    "\n",
    "I will use it to compute the mean of the sentiment score in order to relate it with other features of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Defining the hyperparameters\n",
    "n_iterations = 1000\n",
    "sample_size = len(df)\n",
    "boot_means = []\n",
    "\n",
    "# Bootstrapping loop\n",
    "for i in range(n_iterations):\n",
    "    sample = df.sample(n=sample_size, replace=True)\n",
    "    mean = sample['sentiment_score'].mean()\n",
    "    boot_means.append(mean)\n",
    "\n",
    "# Calculating confidence interval\n",
    "ci_lower = np.percentile(boot_means, 2.5)\n",
    "ci_upper = np.percentile(boot_means, 97.5)\n",
    "\n",
    "# The mean of the whole population is between this two points\n",
    "print(f\"Bootstrapped 95% CI for 'sentiment_score': [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "\n",
    "# Plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(boot_means, bins=50, kde=True, color='skyblue')\n",
    "plt.axvline(ci_lower, color='red', linestyle='--', label=f'2.5% ({ci_lower:.3f})')\n",
    "plt.axvline(ci_upper, color='red', linestyle='--', label=f'97.5% ({ci_upper:.3f})')\n",
    "plt.axvline(np.mean(boot_means), color='green', linestyle='-', label=f'Mean ({np.mean(boot_means):.3f})')\n",
    "plt.title(\"Bootstrapped Means of Sentiment Score\")\n",
    "plt.xlabel(\"Mean Sentiment Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ec319",
   "metadata": {},
   "source": [
    "Conclusion: Since the sentiment score range is [-1,1], we can extract from here that most of the videos are slightly \"positive\" (at least when referring the vocabulary used) more than \"negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af513f0",
   "metadata": {},
   "source": [
    "# Mean sentiment score depending on the topic/country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eaf04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_iterations = 1000\n",
    "boot_results = []\n",
    "\n",
    "# Group by topic and run bootstrapping\n",
    "for topic, group in df.groupby('topic'):\n",
    "    scores = group['sentiment_score'].dropna()\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        # \"replace=True\" means that each row can be selected more than once per group\n",
    "        sample = scores.sample(n=len(scores), replace=True)\n",
    "        boot_results.append({\n",
    "            'topic': topic,\n",
    "            'boot_mean': sample.mean()\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "boot_df = pd.DataFrame(boot_results)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(data=boot_df, x='topic', y='boot_mean', palette='Set2', inner='quartile')\n",
    "plt.title(\"Bootstrapped Mean Sentiment Score by Topic\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Bootstrapped Mean Sentiment Score\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03303874",
   "metadata": {},
   "source": [
    "Conclusion: As expected, both topics have a majority of positive vocabulary, this suggests that the language used in both topics, despite the challenging or sensitive nature, includes positive terms that may frame the topics in a way that encourages positive sentiments. \n",
    "\n",
    "Abortion related content has a grater score on most of the videos, since it is a associated to positive feelings such as \"independence\" or \"freedom\". These emotions are often connected with empowerment or rights which encourages positive sentiments. The negative sentiments for the war topic are reflected in the lower sentiment, as they are tied to the harsher and more distressing realities of war (deaths, destructions, sadness)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e9bfb",
   "metadata": {},
   "source": [
    "Sentiment score by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8bbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_iterations = 1000\n",
    "boot_data = []\n",
    "\n",
    "# Group by 'countries'\n",
    "for country, group in df.groupby('countries'):\n",
    "    scores = group['sentiment_score'].dropna()\n",
    "    \n",
    "    means = []\n",
    "    for _ in range(n_iterations):\n",
    "        sample = scores.sample(n=len(scores), replace=True)\n",
    "        means.append(sample.mean())\n",
    "    \n",
    "    ci_lower = np.percentile(means, 2.5)\n",
    "    ci_upper = np.percentile(means, 97.5)\n",
    "    boot_data.append({\n",
    "        'country': country,\n",
    "        'mean': np.mean(means),\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "boot_df = pd.DataFrame(boot_data)\n",
    "boot_df.sort_values(by='mean', ascending=False, inplace=True)\n",
    "\n",
    "# Plot\n",
    "plot = boot_df.head(15)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(plot['country'], plot['mean'], yerr=[plot['mean'] - plot['ci_lower'], plot['ci_upper'] - plot['mean']],\n",
    "        capsize=5, color='skyblue', edgecolor='black')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Bootstrapped Mean Sentiment Score')\n",
    "plt.title('Mean Sentiment Score with 95% CI')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d6bd8",
   "metadata": {},
   "source": [
    "All five countries exhibit a general trend of maintaining a positive mean sentiment score. However, Poland and Germany report the lowest sentiment scores among them. These discrepancies can be attributed to the distinct sociopolitical contexts each country faces.\n",
    "\n",
    "While both Poland and Germany have long since legalized abortion, their geographical proximity to the ongoing Russia-Ukraine conflict may contribute to a heightened awareness of the surrounding geopolitical tensions. This proximity could lead to a more somber or negative tone in discussions surrounding sensitive topics such as abortion and war, in contrast to the other countries in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62996d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of bootstrap iterations\n",
    "n_iterations = 1000\n",
    "\n",
    "# Function to compute bootstrapped confidence intervals\n",
    "def bootstrap_ci(data, n_iterations=1000, percentile_range=(2.5, 97.5)):\n",
    "    boot_means = []\n",
    "    for _ in range(n_iterations):\n",
    "        sample = data.sample(n=len(data), replace=True)\n",
    "        boot_means.append(sample.mean())\n",
    "    ci_lower = np.percentile(boot_means, percentile_range[0])\n",
    "    ci_upper = np.percentile(boot_means, percentile_range[1])\n",
    "    return ci_lower, ci_upper\n",
    "\n",
    "# Create a combined plot for all countries\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Loop through each country in the dataframe\n",
    "for country, group in df.groupby('countries'):\n",
    "    # Iterate through each topic within the country\n",
    "    for topic, topic_data in group.groupby('topic'):\n",
    "        # Get bootstrapped confidence intervals for the sentiment score of each topic\n",
    "        ci_lower, ci_upper = bootstrap_ci(topic_data['sentiment_score'])\n",
    "        \n",
    "        # Plot the confidence intervals, using country as a label for each line\n",
    "        plt.plot([topic, topic], [ci_lower, ci_upper], marker='o', markersize=8, label=f'{country} - {topic}')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Bootstrapped 95% CI of Sentiment Scores by Topic and Country')\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a legend to differentiate countries\n",
    "plt.legend(title='Country - Topic', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff4d24",
   "metadata": {},
   "source": [
    "Low sentiment score when referring to abortion could also be explained by the presence of right-associated ideology which is usually relation to anti-abortion discourse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac33c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by country and calculate mean for '% left' and '% right'\n",
    "mean_ideology = df.groupby('countries')[['% left', '% right']].mean().reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(mean_ideology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225700c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Filter for abortion-related content\n",
    "abortion_df = df[df['topic'].str.lower() == 'abortion']\n",
    "\n",
    "# 2. Drop rows with missing values in sentiment or % right\n",
    "abortion_clean = abortion_df[['sentiment_score', '% right']].dropna()\n",
    "\n",
    "# 3. Correlation\n",
    "correlation = abortion_clean['sentiment_score'].corr(abortion_clean['% right'])\n",
    "print(f\"Correlation between sentiment score and % right (abortion videos): {correlation:.3f}\")\n",
    "\n",
    "# 4. Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(data=abortion_clean, x='% right', y='sentiment_score', scatter_kws={'s': 50}, line_kws={'color': 'red'})\n",
    "plt.title('Sentiment Score vs % Right (Abortion Content)')\n",
    "plt.xlabel('% Right')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3e5b6",
   "metadata": {},
   "source": [
    "As observed, there is a negative correlation between the percentage of right-leaning language and sentiment score in abortion-related content. This suggests that a higher presence of right-leaning ideological framing is associated with more negative sentiment when discussing abortion.\n",
    "\n",
    "This pattern could help explain Poland’s notably low sentiment scores, as it is the country with the highest percentage of right-leaning discourse in the dataset. In contrast, this explanation does not fully apply to Germany, which also shows lower sentiment scores but does not exhibit a particularly elevated % Right value. Therefore, in Germany’s case, the negative sentiment may stem from other sociopolitical factors or thematic nuances in the content rather than ideological framing alone.\n",
    "\n",
    "That is why it will be interesting to study how the other factors of the dataset might affect the sentiment score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4447f8",
   "metadata": {},
   "source": [
    "# Relating sentiment score with engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the relevant columns\n",
    "cols = ['sentiment_score', 'average_order', 'likes', 'followers']\n",
    "subset = df[cols].dropna()\n",
    "\n",
    "# Pearson correlation\n",
    "correlation_matrix = subset.corr()\n",
    "\n",
    "print(correlation_matrix['sentiment_score'])\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.regplot(data=subset, x='average_order', y='sentiment_score', ax=axes[0], scatter_kws={'alpha':0.3})\n",
    "axes[0].set_title('Sentiment vs. Average Order')\n",
    "\n",
    "sns.regplot(data=subset, x='likes', y='sentiment_score', ax=axes[1], scatter_kws={'alpha':0.3})\n",
    "axes[1].set_title('Sentiment vs. Likes')\n",
    "\n",
    "sns.regplot(data=subset, x='followers', y='sentiment_score', ax=axes[2], scatter_kws={'alpha':0.3})\n",
    "axes[2].set_title('Sentiment vs. Followers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5014e199",
   "metadata": {},
   "source": [
    "The Pearson correlation analysis reveals a very weak negative relationship between sentiment score and both likes (r = -0.09) and followers (r = -0.09). These low coefficients suggest that sentiment is not significantly associated with user engagement, at least in terms of popularity metrics such as likes or follower count.\n",
    "\n",
    "Although the regression plots display a slight downward trend (indicating that higher engagement may coincide with more negative sentiment) this effect appears to be largely driven by a small number of high-engagement outliers. As such, the visual pattern lacks statistical support and should be interpreted with caution.\n",
    "\n",
    "In contrast, the correlation with average order is slightly stronger but still weak (r = 0.15). Interestingly, this weak positive correlation also hints at a possible tendency for videos with lower sentiment scores to rank more prominently, echoing the pattern seen in the plots.\n",
    "\n",
    "While further analysis falls beyond the scope of this work, it would be worth exploring whether content with more negative sentiment tends to perform better or gain more visibility, potentially due to emotional engagement or platform-specific dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be86568",
   "metadata": {},
   "source": [
    "# Relating ideas with the mean sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00748613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of topics of interest\n",
    "topics = [\n",
    "    'subjectivity', 'pain', 'movement', 'negative_emotion', 'religion',\n",
    "    'violence', 'government', 'independence', 'fear', 'trust', 'leader',\n",
    "    'pro_stance', 'moral_dilemma', 'misinformation', 'human_rights',\n",
    "    'abortion_rights', 'war_justification', 'womens_rights'\n",
    "]\n",
    "\n",
    "# Function to perform bootstrapping and return the mean sentiment score\n",
    "def bootstrap_mean(data, n_iterations=1000):\n",
    "    means = []\n",
    "    for _ in range(n_iterations):\n",
    "        sample = data.sample(n=len(data), replace=True)\n",
    "        means.append(sample['sentiment_score'].mean())\n",
    "    return np.mean(means)\n",
    "\n",
    "# Dictionary to hold the bootstrap mean sentiment scores for each topic\n",
    "bootstrap_topic_scores = {}\n",
    "\n",
    "# Compute the bootstrap mean sentiment score for each topic\n",
    "for topic in topics:\n",
    "    subset = df[df[topic] > 0]  # Filter rows where the topic score is greater than 0\n",
    "    if not subset.empty:\n",
    "        mean_boot = bootstrap_mean(subset)\n",
    "        bootstrap_topic_scores[topic] = mean_boot\n",
    "\n",
    "# Sort the bootstrap scores in descending order\n",
    "bootstrap_topic_scores_sorted = dict(sorted(bootstrap_topic_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Output the results\n",
    "print(\"Bootstrap Mean Sentiment Scores for each Topic:\")\n",
    "for topic, score in bootstrap_topic_scores_sorted.items():\n",
    "    print(f\"{topic}: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fa0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "scores_df = pd.DataFrame(list(bootstrap_topic_scores_sorted.items()), columns=['Topic', 'Bootstrap Mean Sentiment Score'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=scores_df, x='Bootstrap Mean Sentiment Score', y='Topic', palette='viridis')\n",
    "plt.title('Bootstrap Mean Sentiment Scores by Topic')\n",
    "plt.xlabel('Mean Sentiment Score')\n",
    "plt.ylabel('Topic')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
